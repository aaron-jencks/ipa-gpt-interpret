{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "id": "ca5a21a1f26a4622"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = load_dataset('iggy12345/rus-pol-edge-probing-phono-feats')",
   "id": "44de49d6c3f3e6b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Average span length",
   "id": "cf5e2faccb87e75b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = dataset.map(lambda x: {'span_length': (((x['windows']['end'][0] - x['windows']['start'][0] + 1) + (x['windows-phoneme']['end'][0] - x['windows-phoneme']['start'][0] + 1)) / 2) if len(x['windows']['start']) > 0 else 0})",
   "id": "76098d45f519c1c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "average_length = 0\n",
    "count = 0\n",
    "for split in dataset:\n",
    "    average_length += sum(dataset[split]['span_length'])\n",
    "    count += len(dataset[split])\n",
    "average_length /= count\n",
    "print('average span length:', average_length)"
   ],
   "id": "5fed2bf2af6a7aff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature Distribution",
   "id": "c15b51ac414e53c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "supports = {}\n",
    "for split in dataset:\n",
    "    supports[split] = {}\n",
    "    for row in dataset[split]:\n",
    "        if len(row['features']) == 0:\n",
    "            continue\n",
    "        feats = row['features'][0]\n",
    "        for feat in feats:\n",
    "            if feat not in supports[split]:\n",
    "                supports[split][feat] = 0\n",
    "            else:\n",
    "                supports[split][feat] += 1"
   ],
   "id": "5c8a8f43c4925b08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('data/mappings.json', 'r') as fp:\n",
    "    phoneme_mappings = json.load(fp)\n",
    "inverse_mappings = {}\n",
    "for k, v in phoneme_mappings['features'].items():\n",
    "    inverse_mappings[v] = k"
   ],
   "id": "5d18e0bb56dd769a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "width = 0.25\n",
    "\n",
    "feature_ticks = np.arange(len(inverse_mappings) * 2)\n",
    "feature_idxs = {}\n",
    "labels = []\n",
    "for feat in phoneme_mappings['features'].keys():\n",
    "    feature_idxs[-phoneme_mappings['features'][feat]] = len(labels)\n",
    "    labels.append(feat + ' N/A')\n",
    "for feat in phoneme_mappings['features'].keys():\n",
    "    feature_idxs[phoneme_mappings['features'][feat]] = len(labels)\n",
    "    labels.append(feat)\n",
    "\n",
    "for si, split in enumerate(supports.keys()):\n",
    "    counts = np.zeros(feature_ticks.shape)\n",
    "    for feat_idx in supports[split].keys():\n",
    "        counts[feature_idxs[feat_idx]] = supports[split][feat_idx]\n",
    "    plt.bar(feature_ticks + [-width, 0, width][si], counts, label=split, width=width)\n",
    "\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(feature_ticks, labels, rotation=90)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Feature Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "1044e5a4b2223df4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature Inventory",
   "id": "502da214ddfaff70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lang_supports = {}\n",
    "for split in dataset:\n",
    "    lang_supports[split] = {}\n",
    "    for row in dataset[split]:\n",
    "        if len(row['features']) == 0:\n",
    "            continue\n",
    "        lang = row['language']\n",
    "        if lang not in lang_supports[split]:\n",
    "            lang_supports[split][lang] = set()\n",
    "        feats = row['features'][0]\n",
    "        for feat in feats:\n",
    "            if feat > 0:\n",
    "                lang_supports[split][lang].add(feat)"
   ],
   "id": "95ded2e58f9d2f06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for split in lang_supports:\n",
    "    split_intersection = lang_supports[split]['rus'] & lang_supports[split]['pol']\n",
    "    rus_invent = lang_supports[split]['rus'] - split_intersection\n",
    "    pol_invent = lang_supports[split]['pol'] - split_intersection\n",
    "    print(split)\n",
    "    print('disjoint inventory:')\n",
    "    print('russian:', rus_invent)\n",
    "    print('polish:', pol_invent)\n",
    "    print('combined:', split_intersection)"
   ],
   "id": "510988c050d6f5c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b530842beb56ee0c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
