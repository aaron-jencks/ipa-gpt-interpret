{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:23.268240Z",
     "start_time": "2025-10-30T22:50:20.808211Z"
    }
   },
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/Documents/github/ipa-gpt-interpret/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:23.274832Z",
     "start_time": "2025-10-30T22:50:23.272932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "database_path = pathlib.Path('references') / \"Features.xlsx\"\n",
    "output_path = pathlib.Path('data') / 'mappings.json'\n",
    "\n",
    "dataset_names = [\n",
    "    'iggy12345/ru-reviews-classification-ipa',\n",
    "    'iggy12345/allegro-reviews-ipa'\n",
    "]"
   ],
   "id": "5bd761a793439e7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset Analysis\n",
    "Because there are multiple unicode representations for IPA symbols, I want to find specifically the ones that we'll work with."
   ],
   "id": "1e136c3dcfeadf86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:25.287328Z",
     "start_time": "2025-10-30T22:50:23.318601Z"
    }
   },
   "cell_type": "code",
   "source": "datasets = list(map(load_dataset, dataset_names))",
   "id": "2221246346db8a30",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:27.659718Z",
     "start_time": "2025-10-30T22:50:25.337840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "characters = set()\n",
    "\n",
    "def collect_characters(ds, split: str):\n",
    "    for row in tqdm(ds[split]):\n",
    "        for ci, c in enumerate(row['text-phoneme']):\n",
    "            characters.add(c)\n",
    "\n",
    "for dataset in datasets:\n",
    "    collect_characters(dataset, 'train')\n",
    "    collect_characters(dataset, 'validation')\n",
    "\n",
    "print(characters)\n"
   ],
   "id": "8b033157d8943885",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45000/45000 [00:01<00:00, 32944.34it/s]\n",
      "100%|██████████| 15000/15000 [00:00<00:00, 33451.37it/s]\n",
      "100%|██████████| 9577/9577 [00:00<00:00, 21243.58it/s]\n",
      "100%|██████████| 1002/1002 [00:00<00:00, 20583.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'«', 'L', 'р', 'ä', 'Ó', 'Y', 'у', '¡', '★', 'ɑ', 'J', '7', '－', '。', 'Р', 'Т', '⭐', '”', '°', 'b', 'з', 'д', 'ʑ', 'ó', '–', '❄', '|', '4', 'ɡ', 'U', 'т', 'ɹ', 'Ю', 'á', 'p', '#', '`', 'ɨ', '&', 'f', 'T', '1', '➖', '*', '\\n', 'Щ', 'К', '✨', '≈', '̃', 'i', 'W', 'ɭ', 'N', 'и', 'ъ', 'P', 't', '⚘', '₽', 'х', 'ə', 'б', 'z', 'ŋ', 'ś', '•', '»', 'З', '◡', 'Ш', '’', '×', 'г', 'Б', 'l', 'M', ';', 'ʂ', 'Н', 'F', '—', '｀', 'о', 'V', '„', 'н', 'е', 'B', '{', 'ф', '（', 'ë', '}', 'ö', 'В', '➕', 'ş', 'Й', 'ж', 'э', 'Ç', 'Г', '´', '♥', 'ʌ', '_', 'щ', '©', 'ы', '5', 'j', 'в', 'М', '✔', '⛔', 'r', 'Е', 'Q', \"'\", '@', '❣', 'ː', '❌', 'I', '✩', '？', 'Х', '~', 'n', '2', 'C', '‘', 'ć', 'ʲ', 'ɵ', 'm', 'ь', 'Я', 'ヽ', '[', 'g', 'x', '\\\\', 'а', 'k', 'd', '❤', 'v', 'ˈ', 'ɔ', 'А', 'я', '％', 'ł', '‼', 'e', 'И', '6', '☝', 'O', 'ɣ', 'y', 'ą', 'R', '-', '∀', 'S', 'ш', 'H', ']', 'X', 'Ы', 'ę', '.', '́', 'ı', '☹', '$', '\"', '№', 'Z', 's', 'ʒ', 'О', '…', 'ω', 'Ф', 'Ł', 'л', '“', 'A', 'с', '，', 'Ч', 'ú', 'h', 'ɕ', 'Ц', 'ʃ', '8', 'ч', '✌', 'D', 'u', '/', 'ц', 'ˌ', '<', 'ɪ', '?', 'ç', '!', 'ß', 'У', ' ', 'Ь', 'K', 'к', '>', '☺', 'é', 'ñ', '℅', '❗', 'ё', 'м', 'ﾉ', '9', 'o', 'a', 'ю', '=', 'ɲ', 'Л', '÷', ':', 'Д', 'c', '）', '♡', '！', '(', '^', ')', 'q', '☆', '3', 'ż', 'й', ',', '0', 'ɛ', 'í', 'С', '+', 'w', 'E', 'G', '%', 'п', 'ü', 'ń', 'Ж', 'П', '️'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:27.856585Z",
     "start_time": "2025-10-30T22:50:27.714098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_excel(database_path)\n",
    "print(df.head())"
   ],
   "id": "d9520262b30f7799",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0 syllabic stress long consonantal sonorant continuant  \\\n",
      "0          ɒ        +      -    -           -        +          +   \n",
      "1          ɑ        +      -    -           -        +          +   \n",
      "2          ɶ        +      -    -           -        +          +   \n",
      "3          a        +      -    -           -        +          +   \n",
      "4          æ        +      -    -           -        +          +   \n",
      "\n",
      "  delayed release approximant tap  ... anterior distributed strident lateral  \\\n",
      "0               0           +   -  ...        0           0        0       -   \n",
      "1               0           +   -  ...        0           0        0       -   \n",
      "2               0           +   -  ...        0           0        0       -   \n",
      "3               0           +   -  ...        0           0        0       -   \n",
      "4               0           +   -  ...        0           0        0       -   \n",
      "\n",
      "  DORSAL high low front back tense  \n",
      "0      +    -   +     -    +     0  \n",
      "1      +    -   +     -    +     0  \n",
      "2      +    -   +     +    -     0  \n",
      "3      +    -   +     -    -     0  \n",
      "4      +    -   +     +    -     0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:27.868897Z",
     "start_time": "2025-10-30T22:50:27.864867Z"
    }
   },
   "cell_type": "code",
   "source": "list(df.columns[1:])",
   "id": "e349e10fd70059e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['syllabic',\n",
       " 'stress',\n",
       " 'long',\n",
       " 'consonantal',\n",
       " 'sonorant',\n",
       " 'continuant',\n",
       " 'delayed release',\n",
       " 'approximant',\n",
       " 'tap',\n",
       " 'trill',\n",
       " 'nasal',\n",
       " 'voice',\n",
       " 'spread gl',\n",
       " 'constr gl',\n",
       " 'LABIAL',\n",
       " 'round',\n",
       " 'labiodental',\n",
       " 'CORONAL',\n",
       " 'anterior',\n",
       " 'distributed',\n",
       " 'strident',\n",
       " 'lateral',\n",
       " 'DORSAL',\n",
       " 'high',\n",
       " 'low',\n",
       " 'front',\n",
       " 'back',\n",
       " 'tense']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:27.917247Z",
     "start_time": "2025-10-30T22:50:27.915247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = {\n",
    "    'mappings': {},\n",
    "    'features': {}\n",
    "}"
   ],
   "id": "1813be79b5b30811",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:27.964055Z",
     "start_time": "2025-10-30T22:50:27.961177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for ci, col in enumerate(list(df.columns)[1:]):\n",
    "    result['features'][col] = ci"
   ],
   "id": "1bfe4cb55c06be8d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:28.020611Z",
     "start_time": "2025-10-30T22:50:28.008625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "found = []\n",
    "not_found = []\n",
    "for ri, row in df.iterrows():\n",
    "    features = []\n",
    "    symbol = row['Unnamed: 0']\n",
    "    symbol = symbol.replace('͡', '')\n",
    "    if symbol not in characters:\n",
    "        not_found.append(symbol)\n",
    "    else:\n",
    "        found.append(symbol)\n",
    "    for col in result['features'].keys():\n",
    "        feat = str(row[col])\n",
    "        if feat == '+':\n",
    "            features.append(result['features'][col])\n",
    "        elif feat == '0':\n",
    "            features.append(-result['features'][col])\n",
    "    result['mappings'][symbol] = features"
   ],
   "id": "aef0dbaa6d7299fe",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:28.063428Z",
     "start_time": "2025-10-30T22:50:28.060993Z"
    }
   },
   "cell_type": "code",
   "source": "print(found)",
   "id": "57dc1de57a40976c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ɑ', 'a', 'ʌ', 'ɔ', 'o', 'ə', 'e', 'ɛ', 'ɵ', 'u', 'ɨ', 'y', 'i', 'ɪ', 'ɲ', 'ŋ', 'ɭ', 'r', 'n', 'm', 'l', 'q', 'ɕ', 'c', 'ç', 'ɣ', 'x', 'k', 'ɡ', 'ʑ', 'ʂ', 'ʒ', 'z', 'v', 't', 'ʃ', 's', 'p', 'f', 'd', 'b', 'w', 'j', 'ɹ', 'h']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:28.114001Z",
     "start_time": "2025-10-30T22:50:28.110744Z"
    }
   },
   "cell_type": "code",
   "source": "print(not_found)",
   "id": "b435d65b8d6a4fa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ɒ', 'ɶ', 'æ', 'ɤ', 'ɘ', 'œ', 'ɞ', 'ø', 'ɯ', 'ʊ', 'ʉ', 'ʏ', 'ŋ+', 'ʟ', 'ɫ', 'ɴ', 'ʀ', 'ʎ', 'ŋ˗', 'ʟ', 'ʟ̠', 'ɳ', 'ʙ', 'ɺ', 'ɻ', 'ɽ', 'ɾ', 'ɱ', 'ʔ', 'ɣ+', 'x+', 'k+', 'ɡ+', 'k+x+', 'ɡ+ɣ+', 'ħ', 'ʕ', 'ʁ', 'χ', 'ɢ', 'ɉ', 'ʝ', 'dʑ', 'tɕ', 'ɣ̠ ', 'x̠', 'k̠', 'ɡ̠', 'ʈ', 'ɖ', 'ɬ', 'ʐ', 'ɸ', 'θ', 'ɮ', 'ð', 'β', 'dʒ', 'dz', 'dɮ', 'd̠ɮ̠', 'tʃ', 't̠ɬ̠', 'ts', 'tɬ', 't̪s̪', 't̪ɬ̪', 'd̪z̪', 'd̪ɮ̪', 'ʈʂ', 'ɖʐ', 'pf', 'bv', 'pɸ', 'bβ', 't̪θ', 'd̪ð', 'cç', 'ɉʝ', 'kx', 'k̠x̠', 'ɡɣ', 'ɡ̠̠ɣ̠', 'qχ', 'ɢʁ', 'ɧ', 'kp', 'gb', 'pt', 'bd', 'ɰ', 'ɰ̠', 'ɥ', 'ʋ', 'ʍ', 'ɦ']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:28.165155Z",
     "start_time": "2025-10-30T22:50:28.161070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "available_symbols = set(found + not_found)\n",
    "not_fulfilled = [c for c in characters if c not in available_symbols]\n",
    "print(not_fulfilled)"
   ],
   "id": "8d962fab124de99d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['«', 'L', 'р', 'ä', 'Ó', 'Y', 'у', '¡', '★', 'J', '7', '－', '。', 'Р', 'Т', '⭐', '”', '°', 'з', 'д', 'ó', '–', '❄', '|', '4', 'U', 'т', 'Ю', 'á', '#', '`', '&', 'T', '1', '➖', '*', '\\n', 'Щ', 'К', '✨', '≈', '̃', 'W', 'N', 'и', 'ъ', 'P', '⚘', '₽', 'х', 'б', 'ś', '•', '»', 'З', '◡', 'Ш', '’', '×', 'г', 'Б', 'M', ';', 'Н', 'F', '—', '｀', 'о', 'V', '„', 'н', 'е', 'B', '{', 'ф', '（', 'ë', '}', 'ö', 'В', '➕', 'ş', 'Й', 'ж', 'э', 'Ç', 'Г', '´', '♥', '_', 'щ', '©', 'ы', '5', 'в', 'М', '✔', '⛔', 'Е', 'Q', \"'\", '@', '❣', 'ː', '❌', 'I', '✩', '？', 'Х', '~', '2', 'C', '‘', 'ć', 'ʲ', 'ь', 'Я', 'ヽ', '[', 'g', '\\\\', 'а', '❤', 'ˈ', 'А', 'я', '％', 'ł', '‼', 'И', '6', '☝', 'O', 'ą', 'R', '-', '∀', 'S', 'ш', 'H', ']', 'X', 'Ы', 'ę', '.', '́', 'ı', '☹', '$', '\"', '№', 'Z', 'О', '…', 'ω', 'Ф', 'Ł', 'л', '“', 'A', 'с', '，', 'Ч', 'ú', 'Ц', '8', 'ч', '✌', 'D', '/', 'ц', 'ˌ', '<', '?', '!', 'ß', 'У', ' ', 'Ь', 'K', 'к', '>', '☺', 'é', 'ñ', '℅', '❗', 'ё', 'м', 'ﾉ', '9', 'ю', '=', 'Л', '÷', ':', 'Д', '）', '♡', '！', '(', '^', ')', '☆', '3', 'ż', 'й', ',', '0', 'í', 'С', '+', 'E', 'G', '%', 'п', 'ü', 'ń', 'Ж', 'П', '️']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We'll have to do some fancy parsing to handle diphthongs, but it looks like the parsing is working correctly and the unicode used for the characters matches the unicode in the datasets themselves.",
   "id": "53b721516cea1567"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:50.706941Z",
     "start_time": "2025-10-30T22:50:50.701852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(output_path, 'w+') as f:\n",
    "    json.dump(result, f, indent=4, ensure_ascii=False)"
   ],
   "id": "b498477e55c9db3c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:50:28.258668Z",
     "start_time": "2025-10-30T22:50:28.256948Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b31efbb7eb2c3a98",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
