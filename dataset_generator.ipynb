{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:05.596930Z",
     "start_time": "2025-11-05T14:51:03.779593Z"
    }
   },
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/Documents/github/ipa-gpt-interpret/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:05.605796Z",
     "start_time": "2025-11-05T14:51:05.603600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "database_path = pathlib.Path('references') / \"Features.xlsx\"\n",
    "output_path = pathlib.Path('data') / 'mappings.json'\n",
    "\n",
    "dataset_names = [\n",
    "    'iggy12345/ru-reviews-classification-ipa',\n",
    "    'iggy12345/allegro-reviews-ipa'\n",
    "]"
   ],
   "id": "5bd761a793439e7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset Analysis\n",
    "Because there are multiple unicode representations for IPA symbols, I want to find specifically the ones that we'll work with."
   ],
   "id": "1e136c3dcfeadf86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:08.218581Z",
     "start_time": "2025-11-05T14:51:05.650454Z"
    }
   },
   "cell_type": "code",
   "source": "datasets = list(map(load_dataset, dataset_names))",
   "id": "2221246346db8a30",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:10.477738Z",
     "start_time": "2025-11-05T14:51:08.270988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "characters = set()\n",
    "\n",
    "def collect_characters(ds, split: str):\n",
    "    for row in tqdm(ds[split]):\n",
    "        for ci, c in enumerate(row['text-phoneme']):\n",
    "            characters.add(c)\n",
    "\n",
    "for dataset in datasets:\n",
    "    collect_characters(dataset, 'train')\n",
    "    collect_characters(dataset, 'validation')\n",
    "\n",
    "print(characters)\n"
   ],
   "id": "8b033157d8943885",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45000/45000 [00:01<00:00, 34685.30it/s]\n",
      "100%|██████████| 15000/15000 [00:00<00:00, 35303.89it/s]\n",
      "100%|██████████| 9577/9577 [00:00<00:00, 22156.07it/s]\n",
      "100%|██████████| 1002/1002 [00:00<00:00, 22761.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'?', 'в', '️', 'ë', '2', ',', 'с', 'ˌ', 'з', 'ɪ', 'р', 'N', 'А', 'Ó', '，', 'v', '&', 'ф', '❗', 'я', 'f', 's', '+', 'Е', '∀', 'ą', '。', 'ɛ', 'y', 'c', '“', '☆', 'п', 'Р', 'g', 'á', '℅', '¡', '◡', 'M', 'ę', 'ń', 'P', '*', '%', '!', 'н', ';', '~', 'z', 'ɨ', '！', 'д', 'Ч', 'ɹ', '{', 'О', 'Х', '❣', '‼', ' ', 'ʃ', '•', 'ś', '➖', 'ы', '✔', 'ç', ':', 'ŋ', 'U', 'Ж', 'Ł', 'ɔ', '„', '？', 'м', '6', '[', 'ə', 'Ь', '➕', 'ɡ', '✌', '`', '☝', 'Ы', '☹', '❌', 'ё', 'l', 'Л', 'ч', 'ц', '@', '_', 'K', 'Ц', '–', '№', 'ɑ', 'Б', 'К', '\\n', 'í', '́', 'э', 'Я', 'j', '”', '－', 'о', 'щ', 'Z', 'ヽ', 'ş', 'ʒ', '^', 'L', 'и', 'Ф', 'И', '’', ')', 'у', 'В', 'З', '8', 'q', '×', '°', 'ю', 'n', 'ä', '(', '©', 'r', '％', 'D', 'Т', 'Q', '1', 'Д', 'ż', 'х', 'ı', 'ﾉ', 'ж', '|', 'ú', 'O', 'С', '$', '❄', 'М', 'ɣ', 'T', '✨', '—', 'ö', 'G', 'F', 'б', '<', 'ω', 'к', '₽', '-', '´', 'a', '（', '‘', '≈', 'ʂ', '7', '«', '⛔', 'г', '0', 'o', 'é', 'e', '3', '）', 'x', '⭐', 'й', '>', 'C', 'H', 'S', 't', 'Y', \"'\", 'Н', 'm', '♡', '4', 'd', 'Й', 'w', 'J', '#', '❤', 'ß', 'Ç', 'ш', '\"', '5', '☺', 'k', 'ü', 'b', '9', 'ó', 'ɕ', '…', '★', 'B', 'ʑ', 'П', '̃', 'ć', 'Ю', 'т', 'У', 'л', '»', 'W', ']', '/', 'ɲ', 'ˈ', 'V', 'i', 'R', '.', 'ъ', 'ь', 'ː', 'E', 'Щ', '=', '｀', 'ɵ', 'ʌ', 'p', 'Г', '♥', 'Ш', 'е', 'а', 'u', '÷', 'I', 'A', 'ɭ', '⚘', '✩', 'X', '}', 'h', '\\\\', 'ñ', 'ʲ', 'ł'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:10.666337Z",
     "start_time": "2025-11-05T14:51:10.533939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_excel(database_path)\n",
    "print(df.head())"
   ],
   "id": "d9520262b30f7799",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0 syllabic stress long consonantal sonorant continuant  \\\n",
      "0          ɒ        +      -    -           -        +          +   \n",
      "1          ɑ        +      -    -           -        +          +   \n",
      "2          ɶ        +      -    -           -        +          +   \n",
      "3          a        +      -    -           -        +          +   \n",
      "4          æ        +      -    -           -        +          +   \n",
      "\n",
      "  delayed release approximant tap  ... anterior distributed strident lateral  \\\n",
      "0               0           +   -  ...        0           0        0       -   \n",
      "1               0           +   -  ...        0           0        0       -   \n",
      "2               0           +   -  ...        0           0        0       -   \n",
      "3               0           +   -  ...        0           0        0       -   \n",
      "4               0           +   -  ...        0           0        0       -   \n",
      "\n",
      "  DORSAL high low front back tense  \n",
      "0      +    -   +     -    +     0  \n",
      "1      +    -   +     -    +     0  \n",
      "2      +    -   +     +    -     0  \n",
      "3      +    -   +     -    -     0  \n",
      "4      +    -   +     +    -     0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:10.680226Z",
     "start_time": "2025-11-05T14:51:10.675588Z"
    }
   },
   "cell_type": "code",
   "source": "list(df.columns[1:])",
   "id": "e349e10fd70059e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['syllabic',\n",
       " 'stress',\n",
       " 'long',\n",
       " 'consonantal',\n",
       " 'sonorant',\n",
       " 'continuant',\n",
       " 'delayed release',\n",
       " 'approximant',\n",
       " 'tap',\n",
       " 'trill',\n",
       " 'nasal',\n",
       " 'voice',\n",
       " 'spread gl',\n",
       " 'constr gl',\n",
       " 'LABIAL',\n",
       " 'round',\n",
       " 'labiodental',\n",
       " 'CORONAL',\n",
       " 'anterior',\n",
       " 'distributed',\n",
       " 'strident',\n",
       " 'lateral',\n",
       " 'DORSAL',\n",
       " 'high',\n",
       " 'low',\n",
       " 'front',\n",
       " 'back',\n",
       " 'tense']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:10.727710Z",
     "start_time": "2025-11-05T14:51:10.726086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = {\n",
    "    'mappings': {},\n",
    "    'features': {}\n",
    "}"
   ],
   "id": "1813be79b5b30811",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:10.774028Z",
     "start_time": "2025-11-05T14:51:10.772047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for ci, col in enumerate(list(df.columns)[1:]):\n",
    "    result['features'][col] = ci + 1"
   ],
   "id": "1bfe4cb55c06be8d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:10.829665Z",
     "start_time": "2025-11-05T14:51:10.819338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "found = []\n",
    "not_found = []\n",
    "for ri, row in df.iterrows():\n",
    "    features = []\n",
    "    symbol = row['Unnamed: 0']\n",
    "    symbol = symbol.replace('͡', '')\n",
    "    if symbol not in characters:\n",
    "        not_found.append(symbol)\n",
    "    else:\n",
    "        found.append(symbol)\n",
    "    for col in result['features'].keys():\n",
    "        feat = str(row[col])\n",
    "        if feat == '+':\n",
    "            features.append(result['features'][col])\n",
    "        elif feat == '0':\n",
    "            features.append(-result['features'][col])\n",
    "    result['mappings'][symbol] = features"
   ],
   "id": "aef0dbaa6d7299fe",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:10.877826Z",
     "start_time": "2025-11-05T14:51:10.875366Z"
    }
   },
   "cell_type": "code",
   "source": "print(found)",
   "id": "57dc1de57a40976c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ɑ', 'a', 'ʌ', 'ɔ', 'o', 'ə', 'e', 'ɛ', 'ɵ', 'u', 'ɨ', 'y', 'i', 'ɪ', 'ɲ', 'ŋ', 'ɭ', 'r', 'n', 'm', 'l', 'q', 'ɕ', 'c', 'ç', 'ɣ', 'x', 'k', 'ɡ', 'ʑ', 'ʂ', 'ʒ', 'z', 'v', 't', 'ʃ', 's', 'p', 'f', 'd', 'b', 'w', 'j', 'ɹ', 'h']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:10.929202Z",
     "start_time": "2025-11-05T14:51:10.926027Z"
    }
   },
   "cell_type": "code",
   "source": "print(not_found)",
   "id": "b435d65b8d6a4fa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ɒ', 'ɶ', 'æ', 'ɤ', 'ɘ', 'œ', 'ɞ', 'ø', 'ɯ', 'ʊ', 'ʉ', 'ʏ', 'ŋ+', 'ʟ', 'ɫ', 'ɴ', 'ʀ', 'ʎ', 'ŋ˗', 'ʟ', 'ʟ̠', 'ɳ', 'ʙ', 'ɺ', 'ɻ', 'ɽ', 'ɾ', 'ɱ', 'ʔ', 'ɣ+', 'x+', 'k+', 'ɡ+', 'k+x+', 'ɡ+ɣ+', 'ħ', 'ʕ', 'ʁ', 'χ', 'ɢ', 'ɉ', 'ʝ', 'dʑ', 'tɕ', 'ɣ̠ ', 'x̠', 'k̠', 'ɡ̠', 'ʈ', 'ɖ', 'ɬ', 'ʐ', 'ɸ', 'θ', 'ɮ', 'ð', 'β', 'dʒ', 'dz', 'dɮ', 'd̠ɮ̠', 'tʃ', 't̠ɬ̠', 'ts', 'tɬ', 't̪s̪', 't̪ɬ̪', 'd̪z̪', 'd̪ɮ̪', 'ʈʂ', 'ɖʐ', 'pf', 'bv', 'pɸ', 'bβ', 't̪θ', 'd̪ð', 'cç', 'ɉʝ', 'kx', 'k̠x̠', 'ɡɣ', 'ɡ̠̠ɣ̠', 'qχ', 'ɢʁ', 'ɧ', 'kp', 'gb', 'pt', 'bd', 'ɰ', 'ɰ̠', 'ɥ', 'ʋ', 'ʍ', 'ɦ']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:10.979709Z",
     "start_time": "2025-11-05T14:51:10.976586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "available_symbols = set(found + not_found)\n",
    "not_fulfilled = [c for c in characters if c not in available_symbols]\n",
    "print(not_fulfilled)"
   ],
   "id": "8d962fab124de99d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', 'в', '️', 'ë', '2', ',', 'с', 'ˌ', 'з', 'р', 'N', 'А', 'Ó', '，', '&', 'ф', '❗', 'я', '+', 'Е', '∀', 'ą', '。', '“', '☆', 'п', 'Р', 'g', 'á', '℅', '¡', '◡', 'M', 'ę', 'ń', 'P', '*', '%', '!', 'н', ';', '~', '！', 'д', 'Ч', '{', 'О', 'Х', '❣', '‼', ' ', '•', 'ś', '➖', 'ы', '✔', ':', 'U', 'Ж', 'Ł', '„', '？', 'м', '6', '[', 'Ь', '➕', '✌', '`', '☝', 'Ы', '☹', '❌', 'ё', 'Л', 'ч', 'ц', '@', '_', 'K', 'Ц', '–', '№', 'Б', 'К', '\\n', 'í', '́', 'э', 'Я', '”', '－', 'о', 'щ', 'Z', 'ヽ', 'ş', '^', 'L', 'и', 'Ф', 'И', '’', ')', 'у', 'В', 'З', '8', '×', '°', 'ю', 'ä', '(', '©', '％', 'D', 'Т', 'Q', '1', 'Д', 'ż', 'х', 'ı', 'ﾉ', 'ж', '|', 'ú', 'O', 'С', '$', '❄', 'М', 'T', '✨', '—', 'ö', 'G', 'F', 'б', '<', 'ω', 'к', '₽', '-', '´', '（', '‘', '≈', '7', '«', '⛔', 'г', '0', 'é', '3', '）', '⭐', 'й', '>', 'C', 'H', 'S', 'Y', \"'\", 'Н', '♡', '4', 'Й', 'J', '#', '❤', 'ß', 'Ç', 'ш', '\"', '5', '☺', 'ü', '9', 'ó', '…', '★', 'B', 'П', '̃', 'ć', 'Ю', 'т', 'У', 'л', '»', 'W', ']', '/', 'ˈ', 'V', 'R', '.', 'ъ', 'ь', 'ː', 'E', 'Щ', '=', '｀', 'Г', '♥', 'Ш', 'е', 'а', '÷', 'I', 'A', '⚘', '✩', 'X', '}', '\\\\', 'ñ', 'ʲ', 'ł']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We'll have to do some fancy parsing to handle diphthongs, but it looks like the parsing is working correctly and the unicode used for the characters matches the unicode in the datasets themselves.",
   "id": "53b721516cea1567"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:11.029951Z",
     "start_time": "2025-11-05T14:51:11.026364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(output_path, 'w+') as f:\n",
    "    json.dump(result, f, indent=4, ensure_ascii=False)"
   ],
   "id": "b498477e55c9db3c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T14:51:11.077287Z",
     "start_time": "2025-11-05T14:51:11.075553Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b31efbb7eb2c3a98",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
