{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T22:58:10.078252Z",
     "start_time": "2025-11-14T22:58:07.556096Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "from config import load_config\n",
    "from util.parsing import get_features\n",
    "from util.windowing import make_random_window"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/Documents/github/ipa-gpt-interpret/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "b69c110cdcf4e8e6",
   "metadata": {},
   "source": [
    "## Get and Load Config and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c8d2d0103bc103a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:58:10.095758Z",
     "start_time": "2025-11-14T22:58:10.090080Z"
    }
   },
   "source": [
    "configs = []\n",
    "cfg = load_config(configs)\n",
    "with open(cfg['mappings'], 'r') as fp:\n",
    "    phoneme_mappings = json.load(fp)\n",
    "\n",
    "print(phoneme_mappings)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mappings': {'ɒ': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 25, 27, -28], 'ɑ': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 25, 27, -28], 'ɶ': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 25, 26, -28], 'a': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 25, -28], 'æ': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 25, 26, -28], 'ʌ': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 27], 'ɔ': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 27], 'o': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 27, 28], 'ɤ': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 27, 28], 'ɘ': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 28], 'œ': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 26], 'ə': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23], 'e': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 26, 28], 'ɞ': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23], 'ø': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 26, 28], 'ɛ': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 26], 'ɵ': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 28], 'ɯ': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 24, 27, 28], 'u': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 24, 27, 28], 'ʊ': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 24, 27], 'ɨ': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 24, 28], 'ʉ': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 24, 28], 'y': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 24, 26, 28], 'i': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 24, 26, 28], 'ʏ': [1, 5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 24, 26], 'ɪ': [1, 5, 6, -7, 8, 12, -19, -20, -21, 23, 24, 26], 'ŋ+': [4, 5, -7, 11, 12, -19, -20, -21, 23, 24, 26, -28], 'ʟ': [4, 5, 6, -7, 8, 12, -19, -20, -21, 22, 23, 24, -26, -27, -28], 'ɫ': [4, 5, 6, -7, 8, 12, 18, 19, 22, 23, 27, -28], 'ɴ': [4, 5, -7, 11, 12, -19, -20, -21, 23, 27, -28], 'ʀ': [4, 5, 6, -7, 8, 10, 12, -19, -20, -21, 23, 27, -28], 'ɲ': [4, 5, -7, 11, 12, 18, 20, 23, 24, 26, -28], 'ʎ': [4, 5, 6, -7, 8, 12, 18, 20, 22, 23, 24, 26, -28], 'ŋ': [4, 5, -7, 11, 12, -19, -20, -21, 23, 24, -26, -27, -28], 'ŋ˗': [4, 5, -7, 11, 12, -19, -20, -21, 23, 24, 27, -28], 'ʟ̠': [4, 5, 6, -7, 8, 12, -19, -20, -21, 22, 23, 24, 27, -28], 'ɳ': [4, 5, -7, 11, 12, 18, -24, -25, -26, -27, -28], 'ʙ': [4, 5, 6, -7, 8, 10, 12, 15, -19, -20, -21, -24, -25, -26, -27, -28], 'ɭ': [4, 5, 6, -7, 8, 12, 18, 22, -24, -25, -26, -27, -28], 'ɺ': [4, 5, 6, -7, 8, 9, 12, 18, 19, 22, -24, -25, -26, -27, -28], 'ɻ': [4, 5, 6, -7, 8, 12, 18, -24, -25, -26, -27, -28], 'ɽ': [4, 5, 6, -7, 8, 9, 12, 18, -24, -25, -26, -27, -28], 'r': [4, 5, 6, -7, 8, 10, 12, 18, 19, -24, -25, -26, -27, -28], 'n': [4, 5, -7, 11, 12, 18, 19, -24, -25, -26, -27, -28], 'm': [4, 5, -7, 11, 12, 15, -19, -20, -21, -24, -25, -26, -27, -28], 'l': [4, 5, 6, -7, 8, 12, 18, 19, 22, -24, -25, -26, -27, -28], 'ɾ': [4, 5, 6, -7, 8, 9, 12, 18, 19, -24, -25, -26, -27, -28], 'ɱ': [4, 5, -7, 11, 12, 15, 17, -19, -20, -21, -24, -25, -26, -27, -28], 'ʔ': [4, 14, -19, -20, -21, -24, -25, -26, -27, -28], 'ɣ+': [4, 6, 7, 12, -19, -20, -21, 23, 24, 26, -28], 'x+': [4, 6, 7, -19, -20, -21, 23, 24, 26, -28], 'k+': [4, -19, -20, -21, 23, 24, 26, -28], 'ɡ+': [4, 12, -19, -20, -21, 23, 24, 26, -28], 'k+x+': [4, 7, -19, -20, -21, 23, 24, 26, -28], 'ɡ+ɣ+': [4, 7, 12, -19, -20, -21, 23, 24, 26, -28], 'ħ': [4, 6, 7, -19, -20, -21, 23, 25, 27, -28], 'ʕ': [4, 6, 12, -19, -20, -21, 23, 25, 27, -28], 'ʁ': [4, 6, 7, 12, -19, -20, -21, 23, 27, -28], 'q': [4, -19, -20, -21, 23, 27, -28], 'χ': [4, 6, 7, -19, -20, -21, 23, 27, -28], 'ɢ': [4, 12, -19, -20, -21, 23, 27, -28], 'ɕ': [4, 6, 7, 18, 19, 20, 21, 23, 24, 26, -28], 'ɉ': [4, 12, 18, 20, 23, 24, 26, -28], 'ʝ': [4, 6, 7, 12, 18, 20, 23, 24, 26, -28], 'c': [4, 18, 20, 23, 24, 26, -28], 'ç': [4, 6, 7, 18, 20, 23, 24, 26, -28], 'dʑ': [4, 7, 12, 18, 19, 20, 21, 23, 24, 26, -28], 'tɕ': [4, 7, 18, 19, 20, 21, 23, 24, 26, -28], 'ɣ': [4, 6, 7, 12, -19, -20, -21, 23, 24, -26, -27, -28], 'ɣ̠ ': [4, 6, 7, 12, -19, -20, -21, 23, 24, 27, -28], 'x': [4, 6, 7, -19, -20, -21, 23, 24, -26, -27, -28], 'x̠': [4, 6, 7, -19, -20, -21, 23, 24, 27, -28], 'k': [4, -19, -20, -21, 23, 24, -26, -27, -28], 'k̠': [4, -19, -20, -21, 23, 24, 27, -28], 'ɡ': [4, 12, -19, -20, -21, 23, 24, -26, -27, -28], 'ɡ̠': [4, 12, -19, -20, -21, 23, 24, 27, -28], 'ʑ': [4, 6, 7, 12, 18, 19, 20, 21, 23, 24, 26, -28], 'ʈ': [4, 18, -24, -25, -26, -27, -28], 'ɖ': [4, 12, 18, -24, -25, -26, -27, -28], 'ɬ': [4, 6, 7, 18, 19, 22, -24, -25, -26, -27, -28], 'ʐ': [4, 6, 7, 12, 18, 21, -24, -25, -26, -27, -28], 'ɸ': [4, 6, 7, 15, -19, -20, -21, -24, -25, -26, -27, -28], 'ʂ': [4, 6, 7, 18, 21, -24, -25, -26, -27, -28], 'ʒ': [4, 6, 7, 12, 18, 20, 21, -24, -25, -26, -27, -28], 'z': [4, 6, 7, 12, 18, 19, 21, -24, -25, -26, -27, -28], 'v': [4, 6, 7, 12, 15, 17, -19, -20, -21, -24, -25, -26, -27, -28], 't': [4, 18, 19, -24, -25, -26, -27, -28], 'ʃ': [4, 6, 7, 18, 20, 21, -24, -25, -26, -27, -28], 's': [4, 6, 7, 18, 19, 21, -24, -25, -26, -27, -28], 'p': [4, 15, -19, -20, -21, -24, -25, -26, -27, -28], 'f': [4, 6, 7, 15, 17, -19, -20, -21, -24, -25, -26, -27, -28], 'd': [4, 12, 18, 19, -24, -25, -26, -27, -28], 'b': [4, 12, 15, -19, -20, -21, -24, -25, -26, -27, -28], 'θ': [4, 6, 7, 18, 19, 20, -24, -25, -26, -27, -28], 'ɮ': [4, 6, 7, 12, 18, 19, 22, -24, -25, -26, -27, -28], 'ð': [4, 6, 7, 12, 18, 19, 20, -24, -25, -26, -27, -28], 'β': [4, 6, 7, 12, 15, -19, -20, -21, -24, -25, -26, -27, -28], 'dʒ': [4, 7, 12, 18, 20, 21, -24, -25, -26, -27, -28], 'dz': [4, 7, 12, 18, 19, 21, -24, -25, -26, -27, -28], 'dɮ': [4, 7, 12, 18, 19, 22, -24, -25, -26, -27, -28], 'd̠ɮ̠': [4, 7, 12, 18, 20, 22, -24, -25, -26, -27, -28], 'tʃ': [4, 7, 18, 20, 21, -24, -25, -26, -27, -28], 't̠ɬ̠': [4, 7, 18, 20, 22, -24, -25, -26, -27, -28], 'ts': [4, 7, 18, 19, 21, -24, -25, -26, -27, -28], 'tɬ': [4, 7, 18, 19, 22, -24, -25, -26, -27, -28], 't̪s̪': [4, 7, 18, 19, 20, 21, -24, -25, -26, -27, -28], 't̪ɬ̪': [4, 7, 18, 19, 20, 22, -24, -25, -26, -27, -28], 'd̪z̪': [4, 7, 12, 18, 19, 20, 21, -24, -25, -26, -27, -28], 'd̪ɮ̪': [4, 7, 12, 18, 19, 20, 22, -24, -25, -26, -27, -28], 'ʈʂ': [4, 7, 18, 21, -24, -25, -26, -27, -28], 'ɖʐ': [4, 7, 12, 18, 21, -24, -25, -26, -27, -28], 'pf': [4, 7, 15, 17, -19, -20, -21, -24, -25, -26, -27, -28], 'bv': [4, 7, 12, 15, 17, -19, -20, -21, -24, -25, -26, -27, -28], 'pɸ': [4, 7, 15, -19, -20, -21, -24, -25, -26, -27, -28], 'bβ': [4, 7, 12, 15, -19, -20, -21, -24, -25, -26, -27, -28], 't̪θ': [4, 7, 18, 19, 20, -24, -25, -26, -27, -28], 'd̪ð': [4, 7, 12, 18, 19, 20, -24, -25, -26, -27, -28], 'cç': [4, 7, 18, 20, 23, 24, 26, -28], 'ɉʝ': [4, 7, 12, 18, 20, 23, 24, 26, -28], 'kx': [4, 7, -19, -20, -21, 23, 24, -26, -27, -28], 'k̠x̠': [4, 7, -19, -20, -21, 23, 24, 27, -28], 'ɡɣ': [4, 7, 12, -19, -20, -21, 23, 24, -26, -27, -28], 'ɡ̠̠ɣ̠': [4, 7, 12, -19, -20, -21, 23, 24, 27, -28], 'qχ': [4, 7, -19, -20, -21, 23, 27, -28], 'ɢʁ': [4, 7, 12, -19, -20, -21, 23, 27, -28], 'ɧ': [4, 6, 7, 18, 20, 21, 23, 24, -26, -27, -28], 'kp': [4, 15, -19, -20, -21, 23, 24, -26, -27, -28], 'gb': [4, 12, 15, -19, -20, -21, 23, 24, -26, -27, -28], 'pt': [4, 15, 18, 19, 21, -24, -25, -26, -27, -28], 'bd': [4, 12, 15, 18, 19, 21, -24, -25, -26, -27, -28], 'ɰ': [5, 6, -7, 8, 12, -19, -20, -21, 23, 24, -26, -27, 28], 'ɰ̠': [5, 6, -7, 8, 12, -19, -20, -21, 23, 24, 27, 28], 'w': [5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 24, 27, 28], 'ɥ': [5, 6, -7, 8, 12, 15, 16, -19, -20, -21, 23, 24, 26, 28], 'j': [5, 6, -7, 8, 12, -19, -20, -21, 23, 24, 26, 28], 'ɹ': [5, 6, -7, 8, 12, 18, 20, -24, -25, -26, -27, -28], 'ʋ': [5, 6, -7, 8, 12, 15, 17, -19, -20, -21, -24, -25, -26, -27, -28], 'ʍ': [6, 7, 13, 15, 16, -19, -20, -21, 23, 24, 27, 28], 'ɦ': [6, 7, 12, 13, -19, -20, -21, -24, -25, -26, -27, -28], 'h': [6, 7, 13, -19, -20, -21, -24, -25, -26, -27, -28]}, 'features': {'syllabic': 1, 'stress': 2, 'long': 3, 'consonantal': 4, 'sonorant': 5, 'continuant': 6, 'delayed release': 7, 'approximant': 8, 'tap': 9, 'trill': 10, 'nasal': 11, 'voice': 12, 'spread gl': 13, 'constr gl': 14, 'LABIAL': 15, 'round': 16, 'labiodental': 17, 'CORONAL': 18, 'anterior': 19, 'distributed': 20, 'strident': 21, 'lateral': 22, 'DORSAL': 23, 'high': 24, 'low': 25, 'front': 26, 'back': 27, 'tense': 28}}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e56d13dc0cf54785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:59:51.961541Z",
     "start_time": "2025-11-14T22:59:47.451029Z"
    }
   },
   "source": [
    "rd = load_dataset(cfg['datasets']['russian'])\n",
    "rd = rd.map(lambda x: {'language': 'rus'}, keep_in_memory=False)\n",
    "pd = load_dataset(cfg['datasets']['polish'])\n",
    "pd = pd.map(lambda x: {'language': 'pol'}, keep_in_memory=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 45000/45000 [00:01<00:00, 31646.29 examples/s]\n",
      "Map: 100%|██████████| 15000/15000 [00:00<00:00, 32100.40 examples/s]\n",
      "Map: 100%|██████████| 15000/15000 [00:00<00:00, 29342.49 examples/s]\n",
      "Map: 100%|██████████| 9577/9577 [00:00<00:00, 41486.59 examples/s]\n",
      "Map: 100%|██████████| 1006/1006 [00:00<00:00, 34158.56 examples/s]\n",
      "Map: 100%|██████████| 1002/1002 [00:00<00:00, 35519.71 examples/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "47f904982460498b",
   "metadata": {},
   "source": [
    "## Generate Windows"
   ]
  },
  {
   "cell_type": "code",
   "id": "726867e529de8ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:00:24.406303Z",
     "start_time": "2025-11-14T23:00:24.400972Z"
    }
   },
   "source": [
    "def preprocess(example):\n",
    "    sentence = example['text']\n",
    "    phoneme_sentence = example['text-phoneme']\n",
    "\n",
    "    window_settings = cfg['windows']\n",
    "    min_window_length = window_settings['min_size']\n",
    "    max_window_length = window_settings['max_size']\n",
    "    window_length_decay = window_settings['size_decay']\n",
    "\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    because the phonemizer is word-level, you can use spaces to create boundaries for your windows\n",
    "    by doing that you can create windows for both the phonetic and the orthographic columns.\n",
    "\n",
    "    I'll leave it up to you as to how you want to encode the data into the dataset, but I'll tell you we need:\n",
    "    1. The window start and stop characters\n",
    "    2. The phonological features present in the span\n",
    "    3. You need a window for both the orthographic column and the phonetic column\n",
    "        * If you want to use the same window that's fine, but then the window offsets need to be word-based instead of character based.\n",
    "        * You can see my implementation of the question answering datasets to see how you can use dicts in dataset columns: https://huggingface.co/datasets/iggy12345/sberquad-ipa (specifically see `answers` and `answers-phoneme`)\n",
    "    \"\"\"\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    # Skip too short sentences\n",
    "    if min(max_window_length, len(phoneme_sentence)) <= min_window_length:\n",
    "        return {\n",
    "            'windows': {'start': [], 'end': []},\n",
    "            'windows-phoneme': {'start': [], 'end': []},\n",
    "            'features': []\n",
    "        }\n",
    "    \n",
    "    start_phoneme_char, end_phoneme_char = make_random_window(\n",
    "        phoneme_sentence,\n",
    "        max_window_length,\n",
    "        min_window_length,\n",
    "        window_length_decay,\n",
    "        set(phoneme_mappings[\"mappings\"].keys())\n",
    "    )\n",
    "\n",
    "    phoneme_sentence_window = phoneme_sentence[start_phoneme_char:end_phoneme_char+1]\n",
    "    spaces_before = phoneme_sentence[0:start_phoneme_char].count(' ')\n",
    "    spaces_within = phoneme_sentence[start_phoneme_char:end_phoneme_char+1].count(' ')\n",
    "\n",
    "    start_word_idx = spaces_before\n",
    "    words_in_window = spaces_within + 1\n",
    "    end_word_idx = start_word_idx + words_in_window - 1\n",
    "\n",
    "    words = sentence.split(' ')\n",
    "    feature_results = get_features(phoneme_sentence_window, phoneme_mappings[\"mappings\"])\n",
    "\n",
    "    start_character_position = sum(len(w) for w in words[0:start_word_idx]) + start_word_idx\n",
    "    end_character_position = sum(len(w) for w in words[start_word_idx:end_word_idx+1]) + (end_word_idx - start_word_idx) + start_character_position - 1\n",
    "\n",
    "    result = {\n",
    "        'windows': {\n",
    "            'start': [start_character_position],\n",
    "            'end': [end_character_position]\n",
    "        },\n",
    "        'windows-phoneme': {\n",
    "            'start': [start_phoneme_char],\n",
    "            'end': [end_phoneme_char]\n",
    "        },\n",
    "        'features': [feature_results]\n",
    "    }\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "bfa886c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:04:45.922742Z",
     "start_time": "2025-11-14T23:04:38.252159Z"
    }
   },
   "source": [
    "keep_columns = ['text', 'text-phoneme', 'language']\n",
    "\n",
    "import time\n",
    "timestamp = int(time.time())\n",
    "\n",
    "rd_sampled = rd.map(\n",
    "    preprocess,\n",
    "    remove_columns=[c for c in rd['train'].column_names if c not in keep_columns],\n",
    "    # cache_file_names={\n",
    "    #     'train': f'C:/Users/wayne/.cache/huggingface/datasets/cache_rd_train_{timestamp}.arrow',\n",
    "    #     'validation': f'C:/Users/wayne/.cache/huggingface/datasets/cache_rd_val_{timestamp}.arrow',\n",
    "    #     'test': f'C:/Users/wayne/.cache/huggingface/datasets/cache_rd_test_{timestamp}.arrow'\n",
    "    # },\n",
    "    # load_from_cache_file=False\n",
    ")\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "pd_sampled = pd.map(\n",
    "    preprocess,\n",
    "    remove_columns=[c for c in pd['train'].column_names if c not in keep_columns],\n",
    "    # cache_file_names={\n",
    "    #     'train': f'C:/Users/wayne/.cache/huggingface/datasets/cache_pd_train_{timestamp}.arrow',\n",
    "    #     'validation': f'C:/Users/wayne/.cache/huggingface/datasets/cache_pd_val_{timestamp}.arrow',\n",
    "    #     'test': f'C:/Users/wayne/.cache/huggingface/datasets/cache_pd_test_{timestamp}.arrow'\n",
    "    # },\n",
    "    # load_from_cache_file=False\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 45000/45000 [00:04<00:00, 10990.89 examples/s]\n",
      "Map: 100%|██████████| 15000/15000 [00:01<00:00, 12236.43 examples/s]\n",
      "Map: 100%|██████████| 15000/15000 [00:01<00:00, 11813.58 examples/s]\n",
      "Map: 100%|██████████| 9577/9577 [00:00<00:00, 11374.78 examples/s]\n",
      "Map: 100%|██████████| 1006/1006 [00:00<00:00, 10658.40 examples/s]\n",
      "Map: 100%|██████████| 1002/1002 [00:00<00:00, 10238.46 examples/s]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "e1a6e103806d83a",
   "metadata": {},
   "source": [
    "# Concatenate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "73910ebe0a7e6fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:04:46.062144Z",
     "start_time": "2025-11-14T23:04:46.047061Z"
    }
   },
   "source": [
    "combined_ds = {}\n",
    "for split in rd_sampled.keys():\n",
    "    combined_ds[split] = concatenate_datasets([rd_sampled[split], pd_sampled[split]])\n",
    "\n",
    "from datasets import DatasetDict\n",
    "combined_ds = DatasetDict(combined_ds)\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "8c2c4086",
   "metadata": {},
   "source": [
    "### Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "a0df6177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:04:46.105700Z",
     "start_time": "2025-11-14T23:04:46.099722Z"
    }
   },
   "source": [
    "print(\"Checking first 10 examples:\")\n",
    "for i in range(10):\n",
    "    ex = combined_ds['train'][i]\n",
    "    if ex['windows']['start']:\n",
    "        phon_window = ex['text-phoneme'][ex['windows-phoneme']['start'][0]:ex['windows-phoneme']['end'][0]+1]\n",
    "        print(f\"Example {i}: phoneme_window='{phon_window}' -> features={ex['features'][0]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking first 10 examples:\n",
      "Example 0: phoneme_window='ja ʌʒydˈɑɭa' -> features=[1, 4, 5, 6, 7, 8, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
      "Example 1: phoneme_window='he color' -> features=[1, 4, 5, 6, 7, 8, 10, 12, 13, 15, 16, 18, 19, 20, 22, 23, 24, 26, 27, 28, -25, -21]\n",
      "Example 2: phoneme_window='ʒˈɑɭ' -> features=[1, 4, 5, 6, -26, 8, -24, -28, 7, 12, -19, 18, 20, 21, 22, 23, 25, 27]\n",
      "Example 3: phoneme_window='razm' -> features=[1, 4, 5, 6, 7, 8, 10, 11, 12, 15, 18, 19, 21, 23, 25, -28, -27, -26, -24, -20]\n",
      "Example 4: phoneme_window='irnˈuɭ' -> features=[1, 4, 5, 6, 8, 10, 11, 12, 15, 16, 18, 19, 22, 23, 24, 26, 27, 28, -25, -21, -20, -7]\n",
      "Example 5: phoneme_window='ɑɭs' -> features=[1, 4, -28, 6, -26, -24, 5, 8, 7, 12, -20, 18, 19, 21, 22, 23, 25, 27]\n",
      "Example 6: phoneme_window='ejku' -> features=[1, 4, 5, 6, 8, -21, 12, -19, -20, 15, 16, 23, 24, -7, 26, 27, 28]\n",
      "Example 7: phoneme_window='eɭʌ m' -> features=[1, 4, 5, 6, 8, 11, 12, 15, 18, 22, 23, 26, 27, 28, -25, -24, -21, -20, -19, -7]\n",
      "Example 8: phoneme_window='bˈystrʌ' -> features=[1, 4, 5, 6, 7, 8, 10, 12, 15, 16, 18, 19, 21, 23, 24, 26, 27, 28, -25, -20]\n",
      "Example 9: phoneme_window='ɛs dʌst' -> features=[1, 4, -28, 5, -25, -24, 6, 7, 8, -20, 12, 18, 19, 21, 23, 26, 27]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "cd3dca61a4354fac",
   "metadata": {},
   "source": [
    "## Push to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "id": "c18e8917697f75a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:04:46.154371Z",
     "start_time": "2025-11-14T23:04:46.150734Z"
    }
   },
   "source": [
    "# TODO if you get here, you're done! I'll handle pushing the dataset to the cloud\n",
    "\n",
    "target_dataset_name = 'rus-pol-edge-probing-phono-feats'\n",
    "username = 'iggy12345'"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "5f01136303f33a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:04:50.541124Z",
     "start_time": "2025-11-14T23:04:46.202440Z"
    }
   },
   "source": [
    "combined_ds.push_to_hub(f'{username}/{target_dataset_name}')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]\u001B[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  8.03ba/s]\u001B[A\n",
      "Processing Files (0 / 0): |          |  0.00B /  0.00B            \n",
      "Processing Files (0 / 1):  98%|█████████▊| 18.6MB / 19.0MB, 1.36MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.0MB / 19.0MB, 1.14MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.0MB / 19.0MB,  910kB/s  \n",
      "New Data Upload: 100%|██████████|  910kB /  910kB,  910kB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.89s/ shards]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 25.09ba/s]\n",
      "Processing Files (0 / 0): |          |  0.00B /  0.00B            \n",
      "Processing Files (1 / 1): 100%|██████████| 4.70MB / 4.70MB, 1.62MB/s  \n",
      "New Data Upload: 100%|██████████|  328kB /  328kB, 1.62MB/s  \u001B[A\n",
      "Processing Files (1 / 1): 100%|██████████| 4.70MB / 4.70MB,  820kB/s  \n",
      "New Data Upload: 100%|██████████|  328kB /  328kB,  820kB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.02 shards/s]\n",
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 30.08ba/s]\n",
      "Processing Files (0 / 0): |          |  0.00B /  0.00B            \n",
      "Processing Files (1 / 1): 100%|██████████| 4.71MB / 4.71MB, 1.77MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 4.71MB / 4.71MB, 1.73MB/s  \n",
      "New Data Upload: 100%|██████████|  345kB /  345kB, 1.73MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.61 shards/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/iggy12345/rus-pol-edge-probing-phono-feats/commit/4ae561c46eacc80d364afa754fb53983d4df4b56', commit_message='Upload dataset', commit_description='', oid='4ae561c46eacc80d364afa754fb53983d4df4b56', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/iggy12345/rus-pol-edge-probing-phono-feats', endpoint='https://huggingface.co', repo_type='dataset', repo_id='iggy12345/rus-pol-edge-probing-phono-feats'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2220eaaef25d6b93"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipa-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
